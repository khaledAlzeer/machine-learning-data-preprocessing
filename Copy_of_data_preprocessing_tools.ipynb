{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Import Required Libraries\n",
        "# ================================\n",
        "\n",
        "# 1) NumPy\n",
        "# Used for numerical operations and working with arrays\n",
        "import numpy as np\n",
        "\n",
        "# 2) Matplotlib\n",
        "# Used for data visualization (we mainly use pyplot module)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 3) Pandas\n",
        "# Used for importing datasets and creating:\n",
        "#    - Feature matrix (X)\n",
        "#    - Dependent variable vector (y)\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "D8VJVLUBLDFW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Step 1: Load the Dataset\n",
        "# =========================================\n",
        "\n",
        "# Create a variable to store the dataset (DataFrame)\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# Step 2: Create Two Entities\n",
        "# =========================================\n",
        "\n",
        "# 1) Matrix of Features (Independent Variables)\n",
        "#    These are the columns used to predict the dependent variable.\n",
        "#    Usually, they are all columns except the last one.\n",
        "x = dataset.iloc[:, :-1].values\n",
        "\n",
        "# 2) Dependent Variable Vector\n",
        "#    This is the column we want to predict.\n",
        "#    Usually, it is the last column in the dataset.\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "UVHxOOF2Nsja"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1xWXrrVVTl",
        "outputId": "1c421ad7-5511-4212-a8c5-83a4b8851920"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbzZ3sPAVYBP",
        "outputId": "a2f0998b-6992-4be2-858a-63d37bccd3da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Handling Missing Values\n",
        "# Using Scikit-Learn Library\n",
        "# =========================================\n",
        "\n",
        "# Import SimpleImputer to handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an object from SimpleImputer\n",
        "# missing_values = np.nan  → defines what is considered as missing\n",
        "# strategy = 'mean'        → replace missing values with the mean of the column\n",
        "\n",
        "imputer = SimpleImputer(\n",
        "    missing_values=np.nan,\n",
        "    strategy='mean'\n",
        ")\n",
        "\n",
        "# =========================================\n",
        "# Apply Imputer on Specific Columns\n",
        "# =========================================\n",
        "\n",
        "# x[:, 1:3]  → select columns index 1 and 2\n",
        "# (All rows, columns from 1 up to but not including 3)\n",
        "\n",
        "# Step 1: fit()\n",
        "# Learn the mean of each selected column (ignoring NaN values)\n",
        "imputer.fit(x[:, 1:3])\n",
        "\n",
        "# Step 2: transform()\n",
        "# Replace the missing values with the learned mean\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])\n"
      ],
      "metadata": {
        "id": "dmJMbdXvbuwm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBQW683oiX9J",
        "outputId": "8d54f820-c1d2-40eb-9d71-40b31b655fe8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Encoding Categorical Data (Independent Variable)\n",
        "# =========================================\n",
        "# We use two main preprocessing classes:\n",
        "# 1) ColumnTransformer → to apply a transformation on specific columns only\n",
        "# 2) OneHotEncoder     → to convert categorical values into numerical vectors\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# Create ColumnTransformer Object\n",
        "# =========================================\n",
        "# ('encoder', OneHotEncoder(), [0])\n",
        "# - 'encoder'         → name of the transformation (any name you choose)\n",
        "# - OneHotEncoder()   → the encoding technique\n",
        "# - [0]               → column index that contains categorical data\n",
        "\n",
        "# remainder='passthrough'\n",
        "# → keep the remaining columns unchanged (numerical columns)\n",
        "ct = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('encoder', OneHotEncoder(), [0])\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# Apply Encoding\n",
        "# =========================================\n",
        "# fit_transform():\n",
        "# 1) fit()      → learn the unique categories in column 0\n",
        "# 2) transform()→ convert them into one-hot encoded vectors\n",
        "x = np.array(ct.fit_transform(x))\n"
      ],
      "metadata": {
        "id": "VJkoptphqX-1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HlqeIYetwtZ",
        "outputId": "e9452f5d-0ed9-43f9-d8dd-2594ae058f2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Encoding the Dependent Variable (y)\n",
        "# =========================================\n",
        "\n",
        "# Many machine learning algorithms require the target variable (y) to be numeric.\n",
        "# If y is categorical (e.g., \"Yes\"/\"No\"), we need to convert it into numbers.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create an object from LabelEncoder\n",
        "# We don't pass anything inside the parentheses\n",
        "# because LabelEncoder doesn't need any configuration at creation\n",
        "le = LabelEncoder()\n",
        "\n",
        "\n",
        "# Fit the encoder on y and transform y\n",
        "# - fit(): learns all unique classes in y (e.g., \"Yes\", \"No\")\n",
        "# - transform(): converts each class into a number (e.g., \"No\" → 0, \"Yes\" → 1)\n",
        "# - fit_transform(): does both steps in one line\n",
        "y = le.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "HJL0DumzunLn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkxvzbsovbDr",
        "outputId": "e2385068-a997-4fca-ca85-f2062dd5278f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Splitting the Dataset into Training set and Test set\n",
        "# =========================================\n",
        "\n",
        "# Import train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into:\n",
        "# - x_train → Features used for training the model\n",
        "# - x_test  → Features used for testing the model\n",
        "# - y_train → Target values for training\n",
        "# - y_test  → Target values for testing\n",
        "\n",
        "# test_size=0.2  → 20% of the data will be used for testing\n",
        "# random_state=1 → Ensures reproducibility (same split every time)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y,\n",
        "    test_size=0.2,\n",
        "    random_state=1\n",
        ")"
      ],
      "metadata": {
        "id": "mdwAVm2VC22H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9PpHwt0FAh6",
        "outputId": "a25a3f2a-98dd-440c-cd26-4506d3221972"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTJvtmpyFAnN",
        "outputId": "c0254203-0a9a-40ef-dc3e-94b9ed5f3d17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5IO4c5FFArI",
        "outputId": "8f0c3f9e-7f8a-408f-813a-05f84b3e2ff8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWCCIS0IFAwh",
        "outputId": "1a7478db-002a-4727-9fa7-91e38f6a22a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Feature Scaling using StandardScaler\n",
        "# =========================================\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Apply scaling on training set (columns starting from index 3 onward)\n",
        "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
        "\n",
        "# Apply scaling on test set (using same scaler fitted on training data)\n",
        "x_test[:, 3:] = sc.transform(x_test[:, 3:])\n"
      ],
      "metadata": {
        "id": "wV36ccXLKeSq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrkKxR2pQ7sf",
        "outputId": "3d02e931-90fd-4952-8dfd-b5dc7f58e4c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ldN4fikQ90P",
        "outputId": "ff786625-6f9b-482c-fbb8-18548d2a61d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    }
  ]
}